# 谷粒商城

## Bug 汇总

1. nacos注册要注意  要设置两个服务器地址 ：注册服务器 和 配置服务器
   - bootsrap.properties 设置 config.server-addr 配置服务器地址
   - application.yml 中配置注册服务器地址  
   - 两者区别？为什么在这两个文件分别配置？？？
2. 

# Docker

## Docker安装

- 官网找到一下目录，按教程安装

![image-20210612124654630](C:\Users\sushi\AppData\Roaming\Typora\typora-user-images\image-20210612124654630.png)

## Docker配置

- 配置mysql端口映射和文件挂载

~~~shell
docker run -p 3306:3306 --name mysql  -v /mydata/mysql/log:/var/log/mysql  -v /mydata/mysql/data:/var/lib/mysql  -v /mydata/mysql/conf:/etc/mysql  -e MYSQL_ROOT_PASSWORD=root  -d mysql:5.7
~~~

- 配置redis时，如果Linux本身就有redis要记得停止redis服务

  ~~~shell
  #下载redis
  docker pull redis
  #配置文件
  mkdir -p /mydata/redis/conf
  touch /mydata/redis/conf/redis.conf
  #启动
  docker run -p 6379:6379 --name redis \
  -v /mydata/redis/data:/data \
  -v /mydata/redis/conf/redis.conf:/etc/redis/redis.conf \
  -d redis redis-server /etc/redis/redis.conf
  #查看容器
  docker ps
  #查看所有容器（包括停止了的）
  docker ps -a
  #使用redis-cli模式 进入redis
  docker exec -it redis redis-cli#最后输入的redis-cli表明进入是使用的命令，redis-cli命令是用于进入cli模式的
  
  ~~~

## Docker 使用

![image-20210712202747576](谷粒商城.assets/image-20210712202747576.png)

# 创建项目

1. ## 创建多个子项目，分别对应多个微服务

   - 注意java版本，springboot springcloud spring-alibaba版本是否兼容

2. ## 父项目用于聚合子项目

3. ## 创建脚手架工程（人人）

   1. ### 先搭建renren-fast项目

      - docker的数据库

      - vue前端

   2. ### 使用renren-gennerator生成对应微服务代码，在目标项目整合mybatis-plus

      - gennerator使用: 设置apllication.yml中的数据库连接信息url；设置generator.properties中的微服务模块名，表前缀。

   3. ### 创建common子项目，为其他生成的微服务项目提供依赖

      - 导入必要的类和依赖，下图中的类在renren-fast中都可找到

        ![image-20210612215526825](谷粒商城.assets/image-20210612215526825.png)

      - 依赖

        ~~~xml
        
        <dependencies>
            <dependency>
                <groupId>org.projectlombok</groupId>
                <artifactId>lombok</artifactId>
                <version>1.18.18</version>
            </dependency>
            <!-- https://mvnrepository.com/artifact/org.apache.httpcomponents/httpcore -->
            <dependency>
                <groupId>org.apache.httpcomponents</groupId>
                <artifactId>httpcore</artifactId>
                <version>4.4.14</version>
            </dependency>
            <!--下面这个依赖可以在renren-fast中找到-->
            <dependency>
                <groupId>commons-lang</groupId>
                <artifactId>commons-lang</artifactId>
                <version>2.6</version>
            </dependency>
            <dependency>
                <groupId>com.baomidou</groupId>
                <artifactId>mybatis-plus-boot-starter</artifactId>
                <version>3.4.3</version>
            </dependency>
            <!--        mysql 驱动-->
            <!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java -->
            <dependency>
                <groupId>mysql</groupId>
                <artifactId>mysql-connector-java</artifactId>
                <version>8.0.19</version>
            </dependency>
            <!--servlet 依赖        -->
            <dependency>
                <groupId>javax.servlet</groupId>
                <artifactId>servlet-api</artifactId>
                <version>2.5</version>
                <scope>provided</scope>
            </dependency>
            <dependency>
                <groupId>org.springframework.data</groupId>
                <artifactId>spring-data-redis</artifactId>
                <version>2.2.4.RELEASE</version>
                <scope>compile</scope>
            </dependency>
        </dependencies>
        ~~~

        

   4. ### 导mybatis依赖，跑通生成的微服务子项目

      - 导入common项目，从而导入common已经导入的依赖。

# Spring Cloud alibaba

- ## 特别注意：spring cloud 、springboot 、alibaba 的版本要兼容，否则会出bug

## Common

- 引入 dependenciedManager 管理阿里巴巴相关组件版本
- 引入nacos discovery 依赖

## Nacos 注册和发现    配置

- ## 要注意 注册服务器和 配置服务器地址要分别设置，不能漏掉任何一个，否则服务无法上线

1. ### 下载启动nacos

2. ### 配置应用

   - 导入nacos依赖 （在common 中设置）

   ~~~yml
   <dependency>
        <groupId>com.alibaba.cloud</groupId>
        <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
   </dependency>
   ~~~

   - 配置注册服务器nacos server地址,设置服务端口和名字 （在要注册的服务中设置）
   
     ~~~yaml
     cloud:
         nacos:
             discovery:
                 server-addr: 127.0.0.1:8848  #注册服务器地址
     ~~~
   
     
   
   - bootstrap.properties:  配置服务器地址
   
   ~~~properties
   spring.application.name=gulimall-coupon
   spring.cloud.nacos.config.server-addr=127.0.0.1:8848  ##配置服务器地址
   ~~~
   
   - 使用 @EnableDiscoveryClient 注解开启服务注册与发现功能
   
     ```java
     @SpringBootApplication
     @EnableDiscoveryClient
     public class ProviderApplication {
     
         public static void main(String[] args) {
         	SpringApplication.run(ProviderApplication.class, args);
         }
     
         @RestController
         class EchoController {
             @GetMapping(value = "/echo/{string}")
                 public String echo(@PathVariable String string) {
                 return string;
             }
         }
     }
     ```

## Feign 远程调用

1. ###  在使用远程调用的项目中导入依赖  member

   - ## 	下面的操作都在调用远程服务 的项目member 中操作(member 项目调用 coupons)

2. ### 创建feign包，用于放远程调用的接口

   ~~~java
   /**
   创建对应远程服务的接口
   	a. 使用注解@FeignClient，输入应用名作为参数，开启fein功能
   	b. url映射
   */
   @FeignClient("mall-coupon")//指明要 调用的服务名字
   public interface CouponFeignService {
       @RequestMapping("/coupon/coupon/member/coupons")//被调用的服务url 注意:这个接口放在 member 的feign包里
       public R membercoupons();
   }
   ~~~

   

3. ### 开启feign

   ~~~java
   @SpringBootApplication
   @EnableDiscoveryClient//Nacos 注册发现
   @EnableFeignClients(basePackages = "com.mall.member.feign")//开启远程调用功能，设置feign包
   public class MallMemberApplication {
   
       public static void main(String[] args) {
           SpringApplication.run(MallMemberApplication.class, args);
       }
   
   }
   ~~~

   - bug : No Feign Client for loadBalancing defined. Did you forget to include spring-cloud-starter-loadbalancer?

   - 以下解决方案没用，根本解决方法是配置springboot cloud alibaba版本

     - 在要进行远程调用的子项目的 Pom下添加依赖。bug原因是ribbon和spring自带 loadbalancer 冲突

     - 也可以在common的pom下改依赖，一步到位
   
     ~~~xml
     <dependency>
         <groupId>com.alibaba.cloud</groupId>
         <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
         <exclusions>
             <exclusion>
                 <groupId> springframework.cloud</groupId>
                 <artifactId>spring-cloud-starter-netflix-ribbon</artifactId>
             </exclusion>
         </exclusions>
     </dependency>
     
     <dependency>
         <groupId>org.springframework.cloud</groupId>
         <artifactId>spring-cloud-loadbalancer</artifactId>
         <version>2.2.4.RELEASE</version>
     </dependency>
     ~~~

## Nacos 配置中心

1. ### 导入nacos-config 依赖 (在common 导入即可)

2. ### 创建bootstrap.properties

   ~~~properties
   spring.application.name=gulimall-coupon
   spring.cloud.nacos.config.server-addr=127.0.0.1:8848
   ~~~

3. ### 在配置中心新建配置,配置名:应用名.properties 如:gulimall-coupon.properties。添加配置。应用名是在bootstap中配置的

   ![image-20210712194615321](谷粒商城.assets/image-20210712194615321.png)

   ![image-20210712194552562](谷粒商城.assets/image-20210712194552562.png)

4. ### 动态获取配置

   - ```java
     @RefreshScope//动态获取配置
     
     @Value("${coupon.user.name}")//获取配置
     private String name;
     ```

- 命名空间的使用

  ~~~properties
  ##在bootstrap.properties 中
  spring.cloud.nacos.config.namespace=2bd13948-e715-4470-9596-fecd4cf6727b; ## namespace id ，可在nacos控制面板获得
  ~~~

- 配置集ID （Data ID）文件名

- 配置分组 

- ext-config 读取多个配置

# Spring Gateway

1. ### 使用spring Initializer 创建gateway项目

2. ### 设置nacos配置中心 ，地址、应用名、命名空间

3. ### 配置bootstrap.properties 

   ~~~properties
   spring.cloud.nacos.config.server-addr=127.0.0.1:8848
   spring.application.name=gulimall-gateway
   spring.cloud.nacos.config.namespace=7c6884f9-c17d-4d8b-872d-dd8c2d643aae
   ~~~

4. ### 设置端口 application.properties

   ~~~properties
   spring.cloud.nacos.config.server-addr=127.0.0.1:8848
   spring.application.name=gulimall-gateway
   server.port=88
   ~~~

5. ### 在application.yml中配置 路由规则

   ~~~yaml
   spring: 
     cloud:
       gateway:   
         routes:  
           - id: gg_route
             uri: https://www.google.com
             predicates:
              #请求 带有url 参数 ，并且值等于google 时，使用这个路由规则.？url=google
              #跳转到google
               - Query=url,google 
   ~~~

# 前端

# 商品服务

### 三级分类功能 

#### 编写后端服务，用于查询分类树

#### renren fast vue 添加页面

![image-20210804131725201](谷粒商城.assets/image-20210804131725201.png)

路径product-category 对应vue项目文件位置：

![image-20210804131814430](谷粒商城.assets/image-20210804131814430.png)

#### 注册 到网关，让网关处理请求

- 首先修改vue项目的默认路径为 网关的路径  用全局搜索查找
- ![image-20210713203201687](谷粒商城.assets/image-20210713203201687.png)
- 在nacos中注册renren-fast 用于生成验证码
  - 配置application.yml  添加
    - ![image-20210713203333385](谷粒商城.assets/image-20210713203333385.png)
  - 在启动项目  中启动注册发现功能
  - ![image-20210713203438494](谷粒商城.assets/image-20210713203438494.png)

#### 配置网关的路由规则  gateway application.yml下

~~~yaml
spring:
  cloud:
    gateway:
      routes:
        - id: admin_route
          url: lb://renren-fast #api 开头的请求路由到 renren-fast 服务
          predicates:
            - Path=/api/** ##api 开头的请求
          filters:
            - RewritePath=/api/?(?<segment>.*),/renren-fast/$\{segment} ##重写路径
            ###前端项目请求带上/api/前缀
            ### localhost:88/api/captcha.jpg  ---->  localhost:8080/renren-fast/captcha.jpg
~~~

#### 跨域 详细情况：https://developer.mozilla.org/zh-CN/docs/Web/HTTP/CORS

- 协议、域名、端口都要一致

<img src="谷粒商城.assets/image-20210804134446561.png" alt="image-20210804134446561" style="zoom: 80%;" />

- 非简单请求要先发送预检请求

![image-20210804134552000](谷粒商城.assets/image-20210804134552000.png)

- 如何跨域？
  - niginx 统一域
  - 请求加上access-control 响应头 使用filter 

#### 网关配置跨域filter gateway 里面配置

~~~java
//跨域filter 配置
@Configuration
public class GulimallCorsConfiguration {
    @Bean
    public CorsWebFilter corsWebFilter(){

        UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();
        CorsConfiguration corsConfiguration = new CorsConfiguration();
        //1. 配置跨域
        corsConfiguration.addAllowedHeader("*");
        corsConfiguration.addAllowedMethod("*");
        corsConfiguration.addAllowedOrigin("*");
        corsConfiguration.setAllowCredentials(true);


        source.registerCorsConfiguration("/**",corsConfiguration);
        return new CorsWebFilter(source);
    }
}
~~~



#### 注册product服务

- 在application.yml 中配置 注册中心

  ~~~yaml
  spring:
    cloud:
      nacos:
        discovery:
          server-addr: 127.0.0.1:8848 ##注册中心地址
  ~~~

- 在bootstrap.properties中配置 配置中心

  ~~~yaml
  spring.application.name=gulimall-product ##应用名称
  ##配置中心地址（nacos既能做注册中心也能做配置中）
  spring.cloud.nacos.config.server-addr=127.0.0.1:8848
  ##配置中心的命名空间
  spring.cloud.nacos.config.namespace=b2a2babc-1064-4368-8ba9-012245531791
  ~~~

- 注解 开启服务注册功能

  <img src="谷粒商城.assets/image-20210804141922249.png" alt="image-20210804141922249" style="zoom:67%;" />

#### 前端数据显示

![image-20210804143917993](谷粒商城.assets/image-20210804143917993.png)

- 注意controller存入数据的键为 page 

![image-20210804143933217](谷粒商城.assets/image-20210804143933217.png)

#### 三级分类增删

##### 页面

![image-20210804145620898](谷粒商城.assets/image-20210804145620898.png)

##### 逻辑删除

MP全局配置

~~~yaml
mybatis-plus:
  global-config:
    db-config:
      id-type: auto
      logic-delete-value: 1 ##逻辑已删除值
      logic-not-delete-value: 0 ##逻辑未删除
~~~

在对应实体类字段 加上逻辑删除注解 

~~~java
@TableLogic(value = "1", delval = "0")
private Integer showStatus;
~~~



##### 新增

# 重点

## 阿里云OSS

1.  用户上传文件到应用服务器，应用服务器上传到阿里云
2. 用户向应用服务器请求签名，使用签名直接上传到阿里云

## JSR303 后端数据校验

1. ###  给bean的属性 分别添加校验注解 javax.validation.constraints 包下的注解

2. ### @valid 标注bean,校验bean中各个字段是否合法

   ~~~java
   public class Bean{
       @NotNull
       String name;
   }
   
   
   public class beanTestcontroller{
       
       @RequestMapping("/save")
       public static void test(@valid @RequestBody Bean bean){
   		
       }
   }
   ~~~

3. ### bindingResult 返回校验结果

4. ### 分组校验

   1. ~~~JAVA
      
      public class Bean{
          @NotNull
          String name;
          //根据 CRUD操作类型  标识校验分组
          @NotNUll(message = "修改ID不能为空", group = {UpdateGroup.class}) //修改分组 的情况下触发
          @NotNUll(message = "添加ID必须为空", group = {AddGroup.class})//添加分组  的情况下触发
          
          private int id;
          @URL(message = "URL格式不正确", group = {UpdateGroup.class, AddGroup.class})
          private int logo;
      }
      
      ~~~

   2. ~~~java
      //在controller 中 使用spring 的 @validated 启动校验 
      // 使用@validated 只有标识了分组的才会起作用
      //此时 name不会进行校验
      public class beanTestcontroller{
          
          @RequestMapping("/save")
          public static void addTest(@validated(AddGroup.class) @RequestBody Bean bean){//name没有标识分组   不校验
      		
          }
              
          @RequestMapping("/all")
          public static void addTest(@validated @RequestBody Bean bean){//validated 没有标识分组，只有没有分组的字段name生效
      		
          }
      }
      ~~~

   3. 

# ElasticSearch 

## 原理

### 倒排索引 -- 单词文档矩阵

![image-20210905181702352](谷粒商城.assets/image-20210905181702352.png)

单词文档矩阵描述文档包含哪些单词。搜索引擎的索引就是实现单词 文档矩阵。所以在ES中使用文档表示数据类似Mysql 中的一行记录。索引表示文档的容器，类似Mysql Database。

### ES基本概念

#### 数据

##### Index 索引

名词：相当于Database,用于存储文档

动词：相当于insert 为一个文档创建index

##### Type 

可以理解为Table 已弃用

##### Document

相当于行

#### 结点和集群

##### Cluster 

ES是一个分布式系统，一个集群中有多个结点Node

##### Node

一个结点就是一个ES实例，就是一个Java进程

##### 分片

~~~
一个节点对应一个ES实例；
一个节点可以有多个index（索引）;
一个index可以有多个shard（分片）；
　一个分片是一个lucene index（此处的index是lucene自己的概念，与ES的index不是一回事）；
~~~



## 操作

### 安装和配置

~~~shell
## 下载es 和 kibana可视化
docker pull elasticsearch:7.4.2
docker pull kibana:7.4.2

# 将docker里的目录挂载到linux的/mydata目录中
# 修改/mydata就可以改掉docker里的
mkdir -p /mydata/elasticsearch/config
mkdir -p /mydata/elasticsearch/data

# es可以被远程任何机器访问
echo "http.host: 0.0.0.0" >/mydata/elasticsearch/config/elasticsearch.yml

# 递归更改权限，es需要访问
chmod -R 777 /mydata/elasticsearch/


~~~

### 启动

~~~shell
# 9200是用户交互端口 9300是集群心跳端口
# -e指定是单阶段运行
# -e指定占用的内存大小，生产时可以设置32G
docker run --name elasticsearch -p 9200:9200 -p 9300:9300 \
-e  "discovery.type=single-node" \
-e ES_JAVA_OPTS="-Xms64m -Xmx512m" \
-v /mydata/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \
-v /mydata/elasticsearch/data:/usr/share/elasticsearch/data \
-v  /mydata/elasticsearch/plugins:/usr/share/elasticsearch/plugins \
-d elasticsearch:7.4.2 


# 设置开机启动elasticsearch
docker update elasticsearch --restart=always
~~~

### kibana启动

~~~shell
# kibana指定了了ES交互端口9200  # 5600位kibana主页端口
##注意d
docker run --name kibana -e ELASTICSEARCH_HOSTS=http://192.168.56.10:9200 -p 5601:5601 -d kibana:7.4.2


# 设置开机启动kibana
docker update kibana  --restart=always
~~~

## 检索

### _cat ---- GET请求

![image-20210908231147619](谷粒商城.assets/image-20210908231147619.png)

### 索引一个文档  （保存）  ----PUT  POST 请求

 相当于Insert

保存一个数据，保存在哪个索引的哪个类型下（哪张数据库哪张表下），保存时用唯一标识指定

~~~json
# # 在customer索引下的external类型下保存1号数据
## index: customer
## type: external
PUT customer/external/1

# POSTMAN输入
http://192.168.56.10:9200/customer/external/1

{
 "name":"John Doe"
}
~~~

#### PUT和POST区别

- POST新增。如果不指定id，会自动生成id。指定id就会修改这个数据，并新增版本号；
  - 可以不指定id，不指定id时永远为创建
  - 指定不存在的id为创建
  - 指定存在的id为更新
- PUT可以新增也可以修改。PUT必须指定id；由于PUT需要指定id，我们一般用来做修改操作，不指定id会报错。
  - 必须指定id
  - 版本号总会增加

### 查询 ---- GET 请求

~~~json
GET /customer/external/1

{
    "_index": "customer", //在哪个索引
    "_type": "external", //在哪个类型
    "_id": "1",//记录id
    "_version": 10, //版本号
    "_seq_no": 18,//并发控制字段，每次更新都会+1，用来做乐观锁
    "_primary_term": 6,//记录主分片序号。同上，主分片重新分配，如重启，就会变化
    "found": true,
    "_source": {
        "name": "John Doe" //内容
    }
}
~~~

#### _Version 和 _seq_no 的区别

- version是计算文档更新次数的序号
  - `version` is a sequential number that counts the number of time a document was updated
- seq_no 是记录索引更新次数的序号
  - `_seq_no` is a sequential number that counts the number of operations that happened on the index

#### 乐观并发控制  version 、seq_no 与 primary_term

与ABA问题类似。旧版本使用version 指定版本号。新版本使用seq_no和primary_term(主分片序号) 指定版本号。

### 更新文档 _update

~~~json
POST customer/external/1/_update
{
    "doc":{
        "name":"222"
    }
}
~~~

- POST 可以带_update，检查内容是否真的更新而改变版本号
- PUT不可以

删除

~~~json
DELETE customer/external/1
DELETE customer
//没有删除类型的操作
~~~

### _bulk 批量操作

~~~json
POST http://192.168.56.10:9200/customer/external/_bulk
//执行多条数据
//两行为一个整体
{"index":{"_id":"1"}}
{"name":"a"}
{"index":{"_id":"2"}}
{"name":"b"}
注意格式json和text均不可，要去kibana里Dev Tools
~~~

~~~json
对于整个索引执行批量操作
POST /_bulk
{"delete":{"_index":"website","_type":"blog","_id":"123"}}
{"create":{"_index":"website","_type":"blog","_id":"123"}}
{"title":"my first blog post"}
{"index":{"_index":"website","_type":"blog"}}
{"title":"my second blog post"}
{"update":{"_index":"website","_type":"blog","_id":"123"}}
{"doc":{"title":"my updated blog post"}}

~~~

## 进阶检索

### 搜索文档

ES支持两种基本方式检索；

- 通过REST request uri 发送搜索参数 （uri +检索参数）；
- 通过REST request body 来发送它们（uri+请求体）；一般用这种，称为DSL；

~~~json
示例  使用时不要加#注释内容
GET bank/_search
{
  "query": {  #  查询的字段
    "match_all": {}
  },
  "from": 0,  # 从第几条文档开始查
  "size": 5,
  "_source":["balance"],
  "sort": [
    {
      "account_number": {  # 返回结果按哪个列排序
        "order": "desc"  # 降序
      }
    }
  ]
}
_source为要返回的字段
~~~

### 全文检索

模糊匹配 match

~~~json
GET bank/_search
{
  "query": {
    "match": {
      "address": "kings"
    }
  }
}
~~~

短语匹配 match_phrase 不拆分匹配

~~~json
GET bank/_search
{
  "query": {
    "match_phrase": {
      "address": "mill road"   #  就是说不要匹配只有mill或只有road的，要匹配mill road一整个子串
    }
  }
}
~~~

多字段匹配 multi_match

~~~json
GET bank/_search
{
  "query": {
    "multi_match": {  # 前面的match仅指定了一个字段。
      "query": "mill",
      "fields": [ # state和address有mill子串  不要求都有
        "state",
        "address"
      ]
    }
  }
}
~~~

# Nginx

## 安装

~~~shell
##获取配置文件
docker run -p80:80 --name nginx -d nginx:1.10   
##复制到容器外
docker container cp nginx:/etc/nginx .
##容器已经没用了 停掉 删除
docker stop nginx 
docker rm nginx 

##整理文件结构
[root@VM-0-10-centos mydata]# mv nginx conf
[root@VM-0-10-centos mydata]# ls
conf  elasticsearch  mysql
[root@VM-0-10-centos mydata]# mkdir nginx
[root@VM-0-10-centos mydata]# ls
conf  elasticsearch  mysql  nginx
[root@VM-0-10-centos mydata]# mv conf nginx/
[root@VM-0-10-centos mydata]# ls
elasticsearch  mysql  nginx
[root@VM-0-10-centos mydata]# cd nginx
[root@VM-0-10-centos nginx]# ls
conf


~~~

## 域名和负载均衡

### Nginx反向代理 （类似网关）

<img src="谷粒商城.assets/image-20210909120655376.png" alt="image-20210909120655376"  />

目录结构

![image-20210909122243131](谷粒商城.assets/image-20210909122243131.png)

其中server块的配置单独拆出来做为配置文件.Server 块配置文件位置在http块的include 指定

![image-20210909122159366](谷粒商城.assets/image-20210909122159366.png)

# 性能优化

## 缓存

请求静态资源消耗时间，对静态资源进行缓存。减少响应时间，提高吞吐量。

其他 ：见缓存和分布式锁部分

## 数据库优化

## 业务优化

减少数据库IO操作，一次性把需要检索的数据读进内存

## 关日志

# 缓存和分布式锁

- 即时性、数据一致性要求不高的
- 访问量大而更新频率不高（读多写少） 

## 本地缓存

使用map缓存。问题：不同项目实例或者部署在不同的服务器上会导致数据不一致 

## 分布式缓存

Redis  使用redisTemplate 调用Redis

- 读取数据库之前检查缓存内有没有要查询的数据
  - 如果没有，查询数据库。将查询到的对象转化为JSON，将JSON存入缓存（JSON 跨语言、跨平台）。将JSON转成对象，然后返回。
  - 如果有，将缓存中的JSON转成对象然后返回。

## 缓存问题

### 缓存穿透（查询一定不存在的数据）

- 问题：利用 一定不存在的数据进行查询进行攻击。
- 解决: 对空结果进行缓存，加入过期时间。

### 缓存雪崩 

- 问题：缓存大面积失效。由于key的过期时间相同
- 解决：在原有的失效时间基础上增加随机值。

### 缓存击穿

- 问题： 热点数据失效后、恰好出现大量查询这个热点数据的请求，数据库会进行大量的 热点数据 的重复查询
- 解决：加锁。同样的查询只进行一次查询。

## 分布式锁

使用redis 中的键值对实现。

~~~shell
SET LOCK 1111 NX ## NX 代表数据库中没有 LOCK 这个key 才设置，这个操作是原子的
##上面的代码可能导致死锁
##应该设置过期时间
SET LOCK 1111 EX 30 NX  ##EX ：设置 30s 的过期时间


~~~

![image-20210911205036436](谷粒商城.assets/image-20210911205036436.png)

![image-20210911210930649](谷粒商城.assets/image-20210911210930649.png)

![image-20210911211248443](谷粒商城.assets/image-20210911211248443.png)

![image-20210911210826498](谷粒商城.assets/image-20210911210826498.png)

- 加锁阶段注意问题		
  - 获取锁，执行完查询之后要释放锁(删除锁)
  - 上锁时，key-value 的value 要用于区分锁拥有者
  - 获得锁之后要设置锁过期时间、防止因为服务器出错导致无法释放锁从而导致死锁
- 解锁（删除锁）注意问题
  - 检查当前拥有锁的人是不是自己
  - 解锁时，获取当前锁的值（这个值用于指明拥有锁的人）以及向redis服务器传输删除lock指令都涉及网络通信，会有延迟，破坏了原子性
  - 使用脚本解锁，保证删除锁和对比锁拥有人是原子的。类似CAS
- 锁的续期问题
  - 执行业务的时间过长，还没执行完业务，锁已经过期了。
  - 超时时间设置长一点。 

### Redission

分布式锁框架 ---- 底层是Redis

~~~java
// 参数为锁名字
RLock lock = redissonClient.getLock("CatalogJson-Lock");//该锁实现了JUC.locks.lock接口
lock.lock();//阻塞等待,Redisson 的锁有看门狗机制，不用手动设置超时时间
// 解锁放到finally // 如果这里宕机：有看门狗，不用担心
lock.unlock();
//看门狗原理：
//占锁成功之后设置定时任务 每10s对锁进行续期
//锁默认时间为30s

~~~

~~~java
// 加锁以后10秒钟自动解锁，看门狗不续命
// 无需调用unlock方法手动解锁
lock.lock(10, TimeUnit.SECONDS);

// 尝试加锁，最多等待100秒，上锁以后10秒自动解锁
boolean res = lock.tryLock(100, 10, TimeUnit.SECONDS);
if (res) {
   try {
     ...
   } finally {
       lock.unlock();
   }
}
如果传递了锁的超时时间，就执行脚本，进行占锁;
如果没传递锁时间，使用看门狗的时间，占锁。如果返回占锁成功future，调用future.onComplete();
没异常的话调用scheduleExpirationRenewal(threadId);
重新设置过期时间，定时任务;
//看门狗的原理是定时任务：重新给锁设置过期时间，新的过期时间就是看门狗的默认时间;
//锁时间/3是定时任务周期;

~~~

### 缓存一致性问题

1. 双写模式

   ![image-20210913133151544](谷粒商城.assets/image-20210913133151544.png)

   - 双写模式：写数据库后，写缓存
     - 问题：并发时，2写进入，写完DB后都写缓存。有暂时的脏数据

2. 失效模式

![image-20210913133125783](谷粒商城.assets/image-20210913133125783.png)

- 脏数据问题
- 解决：缓存设置过期时间，定期更新
- 解决：写数据写时，加分布式的读写锁。

### 解决方案

![image-20210913133409133](谷粒商城.assets/image-20210913133409133.png)

### Canal 

![image-20210913141534516](谷粒商城.assets/image-20210913141534516.png)

- Canal 类似Mysql 从数据库。通过监听 biglog 的修改来检查缓存是否失效。

### Spring Cache 

<img src="谷粒商城.assets/image-20210913142942337.png" alt="image-20210913142942337" style="zoom: 67%;" />

## 消息队列

### 作用

- 异步处理

  ![image-20210913200839260](谷粒商城.assets/image-20210913200839260.png)

- 解耦

- 流量控制 削峰

  ![image-20210913200850226](谷粒商城.assets/image-20210913200850226.png)

### 消息队列两个重要的概念

1. 消息代理 Broker：安装了消息中间件的服务器。 接受消息发送者（生产者）的消息，发送到目的地。
2. 目的地，两种：
   1. 队列：点对点
      - 消息生产者发送消息给消息代理，消息代理放到队列中，可以有多个消费者监听队列是否有新消息。
      - 单播：消息只有唯一的发送者和接受者。
   2. 主题：发布订阅模式
      - 多播：发布者发送消息到主题，多个订阅者监听主题。消息到达时订阅者同时收到消息。 

### 消息队列规范

1. JMS

2. AMQP Advanced Message Queuing Protocl

   - ActiedMQ
   - RabbitMQ
   - RocketMQ

   ![image-20210913202445783](谷粒商城.assets/image-20210913202445783.png)

## RabbitMQ

### 基本概念

- Message

  - 组成：消息头 + 消息体
    - 消息头属性：
      - routing-key 路由键
      - priority 优先级
      - delivery-mode
    - 消息体是生产者自己定义的

- Publisher 消息生产者

- Exchange

  - 交换器，负责将消息路由到服务器中的队列

- Queue 消息队列

- Binding 绑定

- Consumer 消息消费者

- Connection 网络连接 TCP

- Channel 信道 

  - 多路复用连接的独立双向数据流通道。信道是建立在真实的TCP连接内的虚拟连接。 

- Brocker 服务器实体

- Virtual Host 虚拟主机

  ![image-20210913222142464](谷粒商城.assets/image-20210913222142464.png)

### connection 和 channel 区别

A Connection represents a real TCP connection to the message broker, whereas aChannelis a virtual connection (AMPQ connection) inside it. This way you can use as many (virtual) connections as you want inside your application without overloading the broker with TCP connections.

You can use one Channel for everything. However, if you have multiple threads, it's suggested to use a different Channel for each thread.
There is no direct relation betweenChannelandQueue. AChannelis used to send AMQP commands to the broker. This can be the creation of a queue or similar, but these concepts are not tied together.

connection 是真实的TCP连接，为了减少建立TCP连接（开销大），引入channel 逻辑连接，对TCP连接进行复用。

### 安装

~~~shell
docker run  -d --name rabbitmq -p 5671:5671 -p 5672:5672 -p 4369:4369 -p 25672:25672 -p 15671:15671 -p 15672:15672 rabbitmq:management

~~~

![image-20210913225542612](谷粒商城.assets/image-20210913225542612.png)

### RabbitMQ运行机制 ---- 消息路由

![image-20210917140956634](谷粒商城.assets/image-20210917140956634.png)

### Exchange 类型

1. ## Direct  完全匹配，单播

   ![image-20210917141422322](谷粒商城.assets/image-20210917141422322.png)

2. ## fanout  局域网广播

   ![image-20210917141533606](谷粒商城.assets/image-20210917141533606.png)

3. ## topic 模式匹配，与Direct 类似

   ![image-20210917141610510](谷粒商城.assets/image-20210917141610510.png)

4. ## headers

### RabbitMQ 消息确认机制 ---- 可靠投递



  

## 定时任务

~~~java
@Slf4j
@Componet 
@EnableSchedule//开启定时功能
@EnableAsync//开启异步任务
pubic class ScheduleTask{
    // cron = "* * * * * * *"
    // 分别代表 秒 分 时 日 月 周 年 
    //spring 不支持年
    // 0/5 代表 每五秒 打印一次。5代表步长
    
    //设置定时任务
    @Scheduled(cron = "*/5 * * * * ?")
    //异步执行
    
    public void hello(){
        log.info("hello");
        
        
    }
}
~~~

